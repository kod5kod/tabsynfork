{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30a6268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import src\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import warnings\n",
    "\n",
    "from tabsyn.latent_utils import recover_data\n",
    "from utils_train import concat_y_to_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80f6bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(\n",
    "    data_path: str,\n",
    "    T: src.Transformations,\n",
    "    task_type,\n",
    "    change_val: bool,\n",
    "    concat = True,\n",
    "):\n",
    "\n",
    "    # classification\n",
    "    if task_type == 'binclass' or task_type == 'multiclass':\n",
    "        X_cat = {} if os.path.exists(os.path.join(data_path, 'X_cat_train.npy'))  else None\n",
    "        X_num = {} if os.path.exists(os.path.join(data_path, 'X_num_train.npy')) else None\n",
    "        y = {} if os.path.exists(os.path.join(data_path, 'y_train.npy')) else None\n",
    "\n",
    "        for split in ['train', 'test']:\n",
    "            X_num_t, X_cat_t, y_t = src.read_pure_data(data_path, split)\n",
    "            if X_num is not None:\n",
    "                X_num[split] = X_num_t\n",
    "            if X_cat is not None:\n",
    "                if concat:\n",
    "                    X_cat_t = concat_y_to_X(X_cat_t, y_t)\n",
    "                X_cat[split] = X_cat_t  \n",
    "            if y is not None:\n",
    "                y[split] = y_t\n",
    "    else:\n",
    "        # regression\n",
    "        X_cat = {} if os.path.exists(os.path.join(data_path, 'X_cat_train.npy')) else None\n",
    "        X_num = {} if os.path.exists(os.path.join(data_path, 'X_num_train.npy')) else None\n",
    "        y = {} if os.path.exists(os.path.join(data_path, 'y_train.npy')) else None\n",
    "\n",
    "        for split in ['train', 'test']:\n",
    "            X_num_t, X_cat_t, y_t = src.read_pure_data(data_path, split)\n",
    "\n",
    "            if X_num is not None:\n",
    "                if concat:\n",
    "                    X_num_t = concat_y_to_X(X_num_t, y_t)\n",
    "                X_num[split] = X_num_t\n",
    "            if X_cat is not None:\n",
    "                X_cat[split] = X_cat_t\n",
    "            if y is not None:\n",
    "                y[split] = y_t\n",
    "\n",
    "    info = src.load_json(os.path.join(data_path, 'info.json'))\n",
    "    \n",
    "\n",
    "    D = src.Dataset(\n",
    "        X_num,\n",
    "        X_cat,\n",
    "        y,\n",
    "        y_info={},\n",
    "        task_type=src.TaskType(info['task_type']),\n",
    "        n_classes=info.get('n_classes')\n",
    "    )\n",
    "    \n",
    "\n",
    "    if change_val:\n",
    "        D = src.change_val(D)\n",
    "\n",
    "    # def categorical_to_idx(feature):\n",
    "    #     unique_categories = np.unique(feature)\n",
    "    #     idx_mapping = {category: index for index, category in enumerate(unique_categories)}\n",
    "    #     idx_feature = np.array([idx_mapping[category] for category in feature])\n",
    "    #     return idx_feature\n",
    "\n",
    "    # for split in ['train', 'val', 'test']:\n",
    "    # D.y[split] = categorical_to_idx(D.y[split].squeeze(1))\n",
    "\n",
    "    D =  src.transform_dataset(D, T, None)\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cb4070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = \"petfinder_tab\"\n",
    "task_type = \"binclass\"\n",
    "dataset_path = \"/Users/leec/lee1carlin@gmail.com - Google Drive/My Drive/gitRepos/tabsynfork/data/petfinder_tab/\"\n",
    "cat_encoding = \"one-hot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1968f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{dataset_path}/info.json', 'r') as f:\n",
    "    info = json.load(f)\n",
    "\n",
    "task_type = info['task_type']\n",
    "# cat_encoding = args.cat_encoding\n",
    "concat = True if task_type == 'regression' else False\n",
    "\n",
    "T_dict = {}\n",
    "\n",
    "T_dict['normalization'] = \"quantile\"\n",
    "T_dict['num_nan_policy'] = 'mean'\n",
    "T_dict['cat_nan_policy'] =  None\n",
    "T_dict['cat_min_frequency'] = None\n",
    "T_dict['cat_encoding'] = cat_encoding\n",
    "T_dict['y_policy'] = \"default\"\n",
    "\n",
    "T = src.Transformations(**T_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffc84673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaNs in numerical features, skipping\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset(\n",
    "        data_path = dataset_path,\n",
    "        T = T,\n",
    "        task_type = task_type,\n",
    "        change_val = False,\n",
    "        concat = concat\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d484cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9434, 11), (9434, 6), (9434, 1), None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.X_num['train'].shape,dataset.X_cat['train'].shape,dataset.y['train'].shape, dataset.n_classes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabsyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
